{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-overview",
   "metadata": {},
   "source": [
    "# GAT — Graph Construction\n",
    "Transforms IMPECT event data into per-possession `torch_geometric.data.Data` objects for a Graph Attention Network.\n",
    "\n",
    "**Graph design:**\n",
    "- **Node** = one action (row) in a possession sequence\n",
    "- **Real edge** i → i+1: the sequential action transition\n",
    "- **Synthetic edge** i → i+2 and i → i+3: long-range synergy links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from kloppy import impect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full event stream so we can detect possession changes correctly\n",
    "MATCH_ID       = 122838\n",
    "COMPETITION_ID = 743\n",
    "\n",
    "dataset = impect.load_open_data(match_id=MATCH_ID, competition_id=COMPETITION_ID)\n",
    "\n",
    "events_df = (\n",
    "    dataset\n",
    "    .transform(to_coordinate_system=\"secondspectrum\")\n",
    "    .to_df(engine=\"pandas\")\n",
    ")\n",
    "\n",
    "# Use the full event stream — NO_VIDEO events are handled at graph-build time\n",
    "df = events_df.copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"Total events: {len(df)}\")\n",
    "print(f\"Event types:  {sorted(df['event_type'].unique().tolist())}\")\n",
    "print(f\"Columns:      {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-timestamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_duration_to_seconds(ts) -> float:\n",
    "    \"\"\"\n",
    "    Convert a Kloppy duration value to float seconds.\n",
    "    Handles pd.Timedelta objects and string formats such as:\n",
    "      '0\\u00b5s', '4s 192999\\u00b5s', '50m 29s 618999\\u00b5s', '24s 350ms', '50m 39s 229ms'\n",
    "    \"\"\"\n",
    "    if ts is None or (isinstance(ts, float) and np.isnan(ts)):\n",
    "        return 0.0\n",
    "    if isinstance(ts, pd.Timedelta):\n",
    "        return ts.total_seconds()\n",
    "    total = 0.0\n",
    "    for part in str(ts).split():\n",
    "        if   part.endswith(\"\\u00b5s\"):  total += float(part[:-2]) / 1_000_000\n",
    "        elif part.endswith(\"ms\"):        total += float(part[:-2]) / 1_000\n",
    "        elif part.endswith(\"m\"):         total += float(part[:-1]) * 60\n",
    "        elif part.endswith(\"s\"):         total += float(part[:-1])\n",
    "    return round(total, 6)\n",
    "\n",
    "\n",
    "# Sanity tests\n",
    "assert abs(parse_duration_to_seconds(\"0\\u00b5s\")                - 0.0)        < 1e-9\n",
    "assert abs(parse_duration_to_seconds(\"4s 192999\\u00b5s\")        - 4.192999)   < 1e-6\n",
    "assert abs(parse_duration_to_seconds(\"50m 29s 618999\\u00b5s\")   - 3029.618999) < 1e-4\n",
    "assert abs(parse_duration_to_seconds(\"24s 350ms\")                - 24.350)     < 1e-6\n",
    "assert abs(parse_duration_to_seconds(\"50m 39s 229ms\")            - 3039.229)   < 1e-4\n",
    "print(\"Timestamp parser OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-encode",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NaN fills ---\n",
    "# team_id: forward-fill so events like NO_VIDEO inherit surrounding team context\n",
    "df[\"team_id\"]           = df[\"team_id\"].ffill()\n",
    "# player_id: some events (e.g. NO_VIDEO) have no player\n",
    "df[\"player_id\"]         = df[\"player_id\"].fillna(\"UNKNOWN\")\n",
    "df[\"pass_type\"]         = df[\"pass_type\"].fillna(\"NONE\")\n",
    "df[\"is_under_pressure\"] = df[\"is_under_pressure\"].fillna(False).astype(bool)\n",
    "df[\"result\"]            = df[\"result\"].fillna(\"NONE\")\n",
    "df[\"success\"]           = df[\"success\"].fillna(False).astype(bool)\n",
    "# Fill start coords before using them to fill end coords\n",
    "df[\"coordinates_x\"]     = df[\"coordinates_x\"].fillna(0.0)\n",
    "df[\"coordinates_y\"]     = df[\"coordinates_y\"].fillna(0.0)\n",
    "df[\"end_coordinates_x\"] = df[\"end_coordinates_x\"].fillna(df[\"coordinates_x\"])\n",
    "df[\"end_coordinates_y\"] = df[\"end_coordinates_y\"].fillna(df[\"coordinates_y\"])\n",
    "\n",
    "# --- Parse timestamps and sort chronologically ---\n",
    "df[\"timestamp_sec\"] = df[\"timestamp\"].apply(parse_duration_to_seconds)\n",
    "df = df.sort_values([\"period_id\", \"timestamp_sec\"]).reset_index(drop=True)\n",
    "\n",
    "# --- Fit encoders on the full match (globally consistent IDs across all graphs) ---\n",
    "player_enc     = LabelEncoder().fit(df[\"player_id\"].astype(str))\n",
    "event_type_enc = LabelEncoder().fit(df[\"event_type\"].astype(str))\n",
    "pass_type_enc  = LabelEncoder().fit(df[\"pass_type\"].astype(str))\n",
    "result_enc     = LabelEncoder().fit(df[\"result\"].astype(str))\n",
    "\n",
    "df[\"player_id_enc\"]   = player_enc.transform(df[\"player_id\"].astype(str))\n",
    "df[\"event_type_enc\"]  = event_type_enc.transform(df[\"event_type\"].astype(str))\n",
    "df[\"pass_type_enc\"]   = pass_type_enc.transform(df[\"pass_type\"].astype(str))\n",
    "df[\"result_enc\"]      = result_enc.transform(df[\"result\"].astype(str))\n",
    "\n",
    "print(f\"Players:     {len(player_enc.classes_)} unique\")\n",
    "print(f\"Event types: {list(event_type_enc.classes_)}\")\n",
    "print(f\"Pass types:  {list(pass_type_enc.classes_)}\")\n",
    "print(f\"Results:     {list(result_enc.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_possessions(df: pd.DataFrame) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split a match DataFrame (all events, sorted chronologically) into\n",
    "    possession sequences.\n",
    "\n",
    "    A new possession begins when:\n",
    "      - team_id changes from the previous event, OR\n",
    "      - the previous event was a SHOT\n",
    "\n",
    "    Returns a list of DataFrames each with a reset 0-based index.\n",
    "    \"\"\"\n",
    "    possessions   = []\n",
    "    current_start = 0\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        prev = df.iloc[i - 1]\n",
    "        curr = df.iloc[i]\n",
    "\n",
    "        if prev[\"team_id\"] != curr[\"team_id\"] or prev[\"event_type\"] == \"SHOT\":\n",
    "            possessions.append(df.iloc[current_start:i].reset_index(drop=True))\n",
    "            current_start = i\n",
    "\n",
    "    possessions.append(df.iloc[current_start:].reset_index(drop=True))\n",
    "    return possessions\n",
    "\n",
    "\n",
    "possessions = segment_possessions(df)\n",
    "lengths     = [len(p) for p in possessions]\n",
    "\n",
    "print(f\"Possessions: {len(possessions)}\")\n",
    "print(f\"Size — min: {min(lengths)}, max: {max(lengths)}, mean: {np.mean(lengths):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "6gz4s4ptcxa",
   "source": "import math\n\n# --- Score constants ---\nFIELD_HALF      = 52.5          # x-axis half-length (m)\nFIELD_LENGTH    = 105.0         # total pitch length (m)\nFIELD_WIDTH     = 68.0          # total pitch width (m)\n# Max distance any point on the field can be from a goal (corner-to-goal diagonal)\nMAX_FIELD_DIST  = (FIELD_LENGTH ** 2 + (FIELD_WIDTH / 2) ** 2) ** 0.5  # ≈ 110.4 m\nSIGMOID_SHIFT   = 7.5           # sigmoid midpoint — gives ≈ 0 at t=0, ≈ 1 at t=15 s\n\n# End-of-play event bonuses\nGOAL_BONUS        =  1.0\nSHOT_BONUS        =  0.3\nOUT_OF_BOUNDS_PEN = -0.1\nINTERCEPT_PEN     = -0.2\n\n\ndef get_attacking_goal_x(team_id: str, period_id: int, home_team_id: str) -> float:\n    \"\"\"\n    Return the x-coordinate of the opponent's goal for the possessing team.\n\n    Convention assumed for Kloppy secondspectrum + IMPECT Bundesliga data:\n      Period 1 — home team attacks toward +x  (opponent's goal at x = +52.5)\n      Period 2 — teams switch; home attacks toward -x (opponent's goal at x = -52.5)\n    \"\"\"\n    is_home = str(team_id) == str(home_team_id)\n    attacks_positive = (is_home and period_id == 1) or (not is_home and period_id == 2)\n    return FIELD_HALF if attacks_positive else -FIELD_HALF\n\n\ndef score_play(play_clean: pd.DataFrame, attacking_goal_x: float) -> float:\n    \"\"\"\n    Compute scalar play score P for one possession sequence (NO_VIDEO removed).\n\n        P = (displacement_scaled * advancement_sq * sigmoid_t) + end_bonus\n\n    Components\n    ----------\n    displacement_scaled : float [-1, 1]\n        How much the ball moved toward the opponent's goal during the play,\n        normalised by MAX_FIELD_DIST (~110.4 m). Negative when the ball moved\n        away from goal, positive when it moved toward goal.\n\n    advancement_sq : float [0, 1]\n        Square of the ball's ending field position along the attack axis.\n        0 = own goal line, 1 = opponent's goal line. Squaring heavily rewards\n        plays that finish deep in the attacking third.\n\n    sigmoid_t : float [0, 1]\n        Logistic sigmoid of (t - 7.5), where t is the play duration in seconds.\n        Starts near 0 at t = 0 and approaches 1 at t = 15 s, rewarding\n        sustained possession.\n\n    end_bonus : float\n        SHOT resulting in GOAL  : +1.0\n        SHOT (no goal)          : +0.3\n        Ball out of bounds      : -0.1   (last result contains 'OUT')\n        Interception            : -0.2   (last event_type == 'INTERCEPTION')\n        Otherwise               :  0.0\n\n    Parameters\n    ----------\n    play_clean : pd.DataFrame\n        Possession rows with NO_VIDEO removed, sorted chronologically.\n    attacking_goal_x : float\n        x-coordinate of the opponent's goal (+52.5 or -52.5).\n\n    Returns\n    -------\n    float : P\n    \"\"\"\n    if len(play_clean) == 0:\n        return 0.0\n\n    first = play_clean.iloc[0]\n    last  = play_clean.iloc[-1]\n\n    x_start = float(first[\"coordinates_x\"])\n    y_start = float(first[\"coordinates_y\"])\n    x_end   = float(last[\"end_coordinates_x\"])\n    y_end   = float(last[\"end_coordinates_y\"])\n    goal_y  = 0.0\n\n    # --- 1. Ball displacement toward goal [-1, 1] ---\n    d_start = ((x_start - attacking_goal_x) ** 2 + (y_start - goal_y) ** 2) ** 0.5\n    d_end   = ((x_end   - attacking_goal_x) ** 2 + (y_end   - goal_y) ** 2) ** 0.5\n    displacement_scaled = min(1.0, (d_start - d_end) / MAX_FIELD_DIST)\n\n    # --- 2. Ball ending field advancement [0, 1], squared ---\n    # 0 = ball at own goal line, 1 = ball at opponent's goal line\n    attack_sign    = 1.0 if attacking_goal_x > 0 else -1.0\n    advancement    = (x_end * attack_sign + FIELD_HALF) / FIELD_LENGTH\n    advancement    = max(0.0, min(1.0, advancement))\n    advancement_sq = advancement ** 2\n\n    # --- 3. Sigmoid of play duration: ≈ 0 at t=0, ≈ 1 at t=15 s ---\n    t     = float(last[\"timestamp_sec\"] - first[\"timestamp_sec\"])\n    sig_t = 1.0 / (1.0 + math.exp(-(t - SIGMOID_SHIFT)))\n\n    mult = displacement_scaled * advancement_sq * sig_t\n\n    # --- 4. End-of-play event bonus ---\n    last_type   = str(last[\"event_type\"])\n    last_result = str(last[\"result\"]).upper()\n\n    if last_type == \"SHOT\":\n        end_bonus = GOAL_BONUS if \"GOAL\" in last_result else SHOT_BONUS\n    elif \"OUT\" in last_result:\n        end_bonus = OUT_OF_BOUNDS_PEN\n    elif last_type == \"INTERCEPTION\":\n        end_bonus = INTERCEPT_PEN\n    else:\n        end_bonus = 0.0\n\n    return mult + end_bonus",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_VIDEO_THRESHOLD = 3.0  # seconds — discard a play if NO_VIDEO exceeds this\n",
    "\n",
    "\n",
    "def build_graph(play: pd.DataFrame, home_team_id: str) -> Data | None:\n",
    "    \"\"\"\n",
    "    Build a PyTorch Geometric Data object from one possession sequence.\n",
    "\n",
    "    NO_VIDEO handling:\n",
    "      - Duration of each event = gap to the next event's timestamp.\n",
    "      - If the total NO_VIDEO duration in the play exceeds NO_VIDEO_THRESHOLD,\n",
    "        the entire play is discarded (return None).\n",
    "      - Otherwise, NO_VIDEO rows are removed before building the graph.\n",
    "\n",
    "    Node features (6):\n",
    "      [player_id_enc, coord_x, coord_y, event_type_enc, timestamp_rel, is_under_pressure]\n",
    "\n",
    "    Edge attributes (7):\n",
    "      [edge_type, pass_type_enc, end_x, end_y, action_distance, result_enc, success]\n",
    "      edge_type: 1.0 = real sequential edge, 2.0 = synthetic long-range edge\n",
    "\n",
    "    g.y : tensor([P]) — play score from score_play()\n",
    "    \"\"\"\n",
    "    # --- NO_VIDEO check ---\n",
    "    timestamps = play[\"timestamp_sec\"].to_numpy()\n",
    "    durations  = np.diff(timestamps)\n",
    "    durations  = np.append(durations, 0.0)\n",
    "\n",
    "    no_video_mask = (play[\"event_type\"] == \"NO_VIDEO\").to_numpy()\n",
    "    if no_video_mask.any():\n",
    "        if durations[no_video_mask].sum() > NO_VIDEO_THRESHOLD:\n",
    "            return None  # too much missing video — discard play\n",
    "\n",
    "    # Remove NO_VIDEO rows; the remaining events form the graph\n",
    "    play_clean = play[~no_video_mask].reset_index(drop=True)\n",
    "\n",
    "    n = len(play_clean)\n",
    "    if n < 2:\n",
    "        return None\n",
    "\n",
    "    play_start_sec = play_clean[\"timestamp_sec\"].iloc[0]\n",
    "\n",
    "    # --- Node features (N, 6) ---\n",
    "    node_features = [\n",
    "        [\n",
    "            float(row[\"player_id_enc\"]),\n",
    "            float(row[\"coordinates_x\"]),\n",
    "            float(row[\"coordinates_y\"]),\n",
    "            float(row[\"event_type_enc\"]),\n",
    "            float(row[\"timestamp_sec\"] - play_start_sec),\n",
    "            float(row[\"is_under_pressure\"]),\n",
    "        ]\n",
    "        for _, row in play_clean.iterrows()\n",
    "    ]\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "    # --- Edges ---\n",
    "    src, dst, attrs = [], [], []\n",
    "    REAL_TYPE  = 1.0\n",
    "    SYNTH_TYPE = 2.0\n",
    "\n",
    "    for i in range(n):\n",
    "        row = play_clean.iloc[i]\n",
    "        x1, y1 = row[\"coordinates_x\"],    row[\"coordinates_y\"]\n",
    "        x2, y2 = row[\"end_coordinates_x\"], row[\"end_coordinates_y\"]\n",
    "        dist    = ((x2 - x1) ** 2 + (y2 - y1) ** 2) ** 0.5\n",
    "\n",
    "        real_attr  = [\n",
    "            REAL_TYPE,\n",
    "            float(row[\"pass_type_enc\"]),\n",
    "            float(x2), float(y2),\n",
    "            float(dist),\n",
    "            float(row[\"result_enc\"]),\n",
    "            float(row[\"success\"]),\n",
    "        ]\n",
    "        synth_attr = [SYNTH_TYPE, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "        if i + 1 < n:  # real sequential edge\n",
    "            src.append(i); dst.append(i + 1); attrs.append(real_attr)\n",
    "        if i + 2 < n:  # synthetic skip-1\n",
    "            src.append(i); dst.append(i + 2); attrs.append(synth_attr)\n",
    "        if i + 3 < n:  # synthetic skip-2\n",
    "            src.append(i); dst.append(i + 3); attrs.append(synth_attr)\n",
    "\n",
    "    edge_index = torch.tensor([src, dst], dtype=torch.long)  # (2, E)\n",
    "    edge_attr  = torch.tensor(attrs, dtype=torch.float)       # (E, 7)\n",
    "\n",
    "    # --- Play score (training label) ---\n",
    "    goal_x = get_attacking_goal_x(\n",
    "        play_clean.iloc[0][\"team_id\"],\n",
    "        play_clean.iloc[0][\"period_id\"],\n",
    "        home_team_id,\n",
    "    )\n",
    "    y = torch.tensor([score_play(play_clean, goal_x)], dtype=torch.float)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-build-all",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_team_id = str(dataset.metadata.teams[0].team_id)\n",
    "\n",
    "graphs  = []\n",
    "skipped = 0\n",
    "\n",
    "for play in possessions:\n",
    "    g = build_graph(play, home_team_id)\n",
    "    if g is None:\n",
    "        skipped += 1\n",
    "    else:\n",
    "        graphs.append(g)\n",
    "\n",
    "scores = [g.y.item() for g in graphs]\n",
    "print(f\"Graphs built:  {len(graphs)}\")\n",
    "print(f\"Skipped:       {skipped}  (single-event plays or NO_VIDEO > {NO_VIDEO_THRESHOLD}s)\")\n",
    "print(f\"Score — min: {min(scores):.3f}, max: {max(scores):.3f}, mean: {np.mean(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-validate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_graphs(graphs: list[Data]) -> None:\n",
    "    sizes = [g.num_nodes for g in graphs]\n",
    "    edges = [g.num_edges for g in graphs]\n",
    "\n",
    "    print(f\"Total graphs: {len(graphs)}\")\n",
    "    print(f\"Nodes — min: {min(sizes)}, max: {max(sizes)}, mean: {np.mean(sizes):.1f}\")\n",
    "    print(f\"Edges — min: {min(edges)}, max: {max(edges)}, mean: {np.mean(edges):.1f}\")\n",
    "\n",
    "    for i, g in enumerate(graphs):\n",
    "        assert g.x.shape[1] == 6,          f\"Graph {i}: node feature width {g.x.shape[1]} != 6\"\n",
    "        assert g.edge_attr.shape[1] == 7,  f\"Graph {i}: edge attr width {g.edge_attr.shape[1]} != 7\"\n",
    "        assert g.edge_index.shape[0] == 2, f\"Graph {i}: edge_index shape {g.edge_index.shape}\"\n",
    "        assert g.edge_index.max().item() < g.num_nodes, f\"Graph {i}: out-of-range node index\"\n",
    "        assert g.y.shape == (1,),          f\"Graph {i}: y shape {g.y.shape} != (1,)\"\n",
    "\n",
    "        n = g.num_nodes\n",
    "        expected = max(0, n - 1) + max(0, n - 2) + max(0, n - 3)\n",
    "        assert g.num_edges == expected, (\n",
    "            f\"Graph {i}: expected {expected} edges for n={n}, got {g.num_edges}\"\n",
    "        )\n",
    "\n",
    "    print(\"All assertions passed.\")\n",
    "\n",
    "    print(\"\\nSample graphs:\")\n",
    "    for g in graphs[:5]:\n",
    "        real  = (g.edge_attr[:, 0] == 1.0).sum().item()\n",
    "        synth = (g.edge_attr[:, 0] == 2.0).sum().item()\n",
    "        print(f\"  nodes={g.num_nodes:>3}, edges={g.num_edges:>3} \"\n",
    "              f\"(real={real:>2}, synthetic={synth:>2})  score={g.y.item():+.4f}\")\n",
    "\n",
    "\n",
    "validate_graphs(graphs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}